{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import collections\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/ly/workspace/mmsa\")\n",
    "from utils.dataset import *\n",
    "from utils.tokenization import BasicTokenizer\n",
    "from utils.load_yelp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_photo(_id:str):\n",
    "    path = os.path.join(DATA_DIR, \"photos\", _id[:2], _id + \".jpg\")\n",
    "    return os.path.exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reviews(file_path:str, clean_data:bool=False) -> List[Dict[str, str]]: \n",
    "    # 读入数据\n",
    "    reviews = None\n",
    "    if file_path.endswith(\".json\"):\n",
    "         with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "            reviews = []\n",
    "            for line in tqdm(f, \"Read json\"):\n",
    "                review = json.loads(line)\n",
    "                imgs = []\n",
    "                captions = []\n",
    "                for photo in review['Photos']:\n",
    "                    _id = photo['_id']\n",
    "                    caption = photo[\"Caption\"]\n",
    "                    if clean_data:\n",
    "                        if check_photo(_id):\n",
    "                            imgs.append(_id)\n",
    "                            captions.append(caption)\n",
    "                    else:\n",
    "                        imgs.append(_id)\n",
    "                        captions.append(caption)\n",
    "                reviews.append({'_id': review['_id'],\n",
    "                      'Text': review['Text'],\n",
    "                      'Photos': imgs,\n",
    "                      'Captions': captions,\n",
    "                      'Rating': review['Rating']})\n",
    "    elif file_path.endswith(\".pickle\"):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            reviews = pickle.load(f) # 直接从pickle中加载\n",
    "    else:\n",
    "        raise RuntimeError(\"Illegal file path!\")\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read json: 35435it [00:01, 33412.25it/s]\n",
      "Read json: 2215it [00:00, 36740.49it/s]\n",
      "Read json: 315it [00:00, 35542.08it/s]\n",
      "Read json: 325it [00:00, 30684.27it/s]\n",
      "Read json: 3730it [00:00, 35776.20it/s]\n",
      "Read json: 1715it [00:00, 21868.18it/s]\n",
      "Read json: 570it [00:00, 1210.24it/s]\n"
     ]
    }
   ],
   "source": [
    "train = read_reviews(train_json, True)\n",
    "valid = read_reviews(valid_json, True)\n",
    "test = {}\n",
    "for city in cities:\n",
    "    test[city] = read_reviews(DATA_DIR + \"raw/test/\" + city + \"_test.json\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"train\" : train, \"valid\" : valid, \"test\" : test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"raw/\" + \"clean_data.pickle\", \"wb\") as o:\n",
    "    pickle.dump(data, o, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = None\n",
    "    with open(DATA_DIR + \"raw/\" + \"clean_data.pickle\", \"rb\") as r:\n",
    "        data = pickle.load(r)\n",
    "    return data\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count word frequency: 100%|██████████| 35435/35435 [00:45<00:00, 785.20it/s]\n",
      "Count word frequency: 100%|██████████| 2215/2215 [00:02<00:00, 807.86it/s]\n"
     ]
    }
   ],
   "source": [
    "freq_dict = count_word_freq(train)\n",
    "freq_dict = count_word_freq(valid, freq_dict)\n",
    "token2idx, idx2token, glove_idx = build_vocab_from_glove(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vocab(DATA_DIR + \"raw/\", token2idx, idx2token, glove_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vocab = load_glove_vocab(DATA_DIR + \"raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token2idx', 'idx2token', 'glove_idx'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_tokenizer = YelpSimpleTokenizer(glove_vocab[\"token2idx\"], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.38 s, sys: 3.99 ms, total: 8.38 s\n",
      "Wall time: 8.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for key in [\"train\", \"valid\"]:\n",
    "#     for i in data[key]:\n",
    "#         i[\"Text\"] = glove_tokenizer.to_idx(i[\"Text\"])\n",
    "for city in cities:\n",
    "    for i in data[\"test\"][city]:\n",
    "        i[\"Text\"] = glove_tokenizer.to_idx(i[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_data():\n",
    "    with open(DATA_DIR + \"raw/\" + \"glove_data.pickle\", \"rb\") as r:\n",
    "        return pickle.load(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"raw/\" + \"glove_data.pickle\", \"wb\") as o:\n",
    "    pickle.dump(data, o, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load glove: 100%|██████████| 400000/400000 [00:06<00:00, 64483.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.33979   ,  0.20941   ,  0.46348   , ..., -0.23394   ,\n",
       "         0.47298   , -0.028803  ],\n",
       "       [-0.038194  , -0.24487   ,  0.72812   , ..., -0.1459    ,\n",
       "         0.8278    ,  0.27062   ],\n",
       "       ...,\n",
       "       [-0.07382662, -0.09844293,  0.03890738, ...,  0.03119204,\n",
       "        -0.04567178,  0.04480205],\n",
       "       [-0.09762643, -0.01279308, -0.09459477, ...,  0.05298445,\n",
       "         0.09622958,  0.00178859],\n",
       "       [ 0.08038855,  0.0121604 ,  0.04316022, ...,  0.05453663,\n",
       "        -0.07731168, -0.02396872]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_yelp_glove_weight(DATA_DIR + \"raw/\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_data = load_glove_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.7(py3.8.5)",
   "language": "python",
   "name": "torch1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
