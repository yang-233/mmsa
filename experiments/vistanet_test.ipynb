{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ly/workspace/mmsa\")\n",
    "seed = 13231\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "from models.vistanet_test import *\n",
    "from utils.train import *\n",
    "from typing import *\n",
    "from collections import Counter\n",
    "\n",
    "from utils.load_yelp import *\n",
    "from utils.dataset import *\n",
    "from utils.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'CLS',\n",
       " 'embedding_dim': 200,\n",
       " 'embedding': None,\n",
       " 'freeze_embedding': False,\n",
       " 'word_hidden_size': 50,\n",
       " 'word_layers': 1,\n",
       " 'word_proj_hidden_size': 100,\n",
       " 'uniform_bound': 0.1,\n",
       " 'sentence_hidden_size': 50,\n",
       " 'sentence_layers': 1,\n",
       " 'sent_proj_hidden_size': 100,\n",
       " 'img_input_size': 4096,\n",
       " 'visual_attention_size': 100,\n",
       " 'dropout': 0.5,\n",
       " 'output_size': 5,\n",
       " 'bias_init': 1.0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = default_config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = load_glove_vgg_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "workers = 6\n",
    "train_loader, valid_loader, test_loader = get_loader(batch_size, workers, get_collate_fn(config), train_set, valid_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ly/miniconda3/envs/torch1.6.0/lib/python3.7/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Total': 9128805, 'Trainable': 9128805}, CrossEntropyLoss())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(config).cuda()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "get_parameter_number(model), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.5 s, sys: 670 ms, total: 4.17 s\n",
      "Wall time: 4.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.18600451467268622, 0.07581024399744264), Counter({4: 4239, 3: 127, 2: 64}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_true, y_pred, _loss = predict(model, valid_loader, loss)\n",
    "evalute(y_true, y_pred), Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "viz = get_Visdom()\n",
    "_interval = 5\n",
    "batch_loss_drawer = VisdomScalar(viz, f\"batch_loss interval:{_interval}\")\n",
    "epoch_loss_drawer = VisdomScalar(viz, f\"Train and valid loss\", 2)\n",
    "acc_drawer = VisdomScalar(viz, \"Train and valid accuracy\", 2)\n",
    "\n",
    "batch_loss = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_acc = []\n",
    "valid_acc = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 1 epoch:: 277it [01:57,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 1 epoch: train_loss:1.354967823484617 train_acc:0.37127944703061083 valid_loss:1.0435471039593354 valid_acc:0.5573363431151241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 2 epoch:: 277it [01:56,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 2 epoch: train_loss:1.2089249277740426 train_acc:0.4372125828748766 valid_loss:0.9804539188305358 valid_acc:0.5959367945823928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 3 epoch:: 277it [01:58,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 3 epoch: train_loss:1.1434450638211822 train_acc:0.4634222034137396 valid_loss:0.9291869199841071 valid_acc:0.609255079006772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 4 epoch:: 277it [01:55,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 4 epoch: train_loss:1.0816361190973744 train_acc:0.494202285230639 valid_loss:0.9268269852106512 valid_acc:0.6015801354401806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 5 epoch:: 277it [01:55,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 5 epoch: train_loss:1.0238314360956124 train_acc:0.5171392297926365 valid_loss:0.9433318780722522 valid_acc:0.5911963882618511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 6 epoch:: 277it [01:57,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 6 epoch: train_loss:0.9524385685072512 train_acc:0.5469318662716885 valid_loss:0.982568848321454 valid_acc:0.5747178329571107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 7 epoch:: 277it [01:58,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 7 epoch: train_loss:0.8854872923809444 train_acc:0.5784736916349273 valid_loss:1.020452000325205 valid_acc:0.5751693002257336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 8 epoch:: 277it [01:57,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 8 epoch: train_loss:0.8210435211111955 train_acc:0.6028494851177881 valid_loss:1.1132246146621876 valid_acc:0.5699774266365688\n",
      "CPU times: user 14min 49s, sys: 1min 22s, total: 16min 12s\n",
      "Wall time: 16min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = 1e-3\n",
    "epoches = 20\n",
    "optimizer = get_regal_optimizer(model, optim.AdamW, lr)\n",
    "res, model = train_visdom(model, optimizer, loss, viz, train_loader,\n",
    "                          valid_loader, epoches, batch_loss, batch_loss_drawer,\n",
    "                          train_loss, valid_loss, epoch_loss_drawer,\n",
    "                          train_acc, valid_acc, acc_drawer,\n",
    "                         _interval=_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_acc': 0.609255079006772,\n",
       " 'max_acc_epoch': 3,\n",
       " 'max_train_acc': 0.4634222034137396,\n",
       " 'max_acc_train_loss': 1.1434450638211822,\n",
       " 'max_acc_valid_loss': 0.9291869199841071,\n",
       " 'last_acc': 0.5699774266365688,\n",
       " 'last_train_acc': 0.6028494851177881,\n",
       " 'last_epoch': 8,\n",
       " 'last_train_loss': 0.8210435211111955,\n",
       " 'last_valid_loss': 1.1132246146621876}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.6060948081264108, 0.602188563002813), 0.9252480728631634)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(model, test_loader, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (word_embedding): Embedding(42834, 200)\n",
       "  (word_encoder): AttentionDynamicRNN(\n",
       "    (rnn): DynamicRNN(\n",
       "      (RNN): GRU(200, 50, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "    )\n",
       "    (proj_fc): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (mask_layer): MaskLayer()\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (padding_layer): PaddingLayer()\n",
       "  (sent_encoder): DynamicRNN(\n",
       "    (RNN): GRU(100, 50, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  )\n",
       "  (sent_proj_fc): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (sent_proj_tanh): Tanh()\n",
       "  (img_proj_fc): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  (img_proj_tanh): Tanh()\n",
       "  (visual_softmax): Softmax(dim=2)\n",
       "  (doc_proj_fc): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (doc_proj_tanh): Tanh()\n",
       "  (doc_visual_softmax): Softmax(dim=1)\n",
       "  (output_layer): OutputLayer(\n",
       "    (fc): Linear(in_features=100, out_features=5, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(valid_loader))\n",
    "X, y = to_cuda((X, y))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.131673 s\n",
       "File: /mnt/disk1/ly/workspace/mmsa/models/vistanet_test.py\n",
       "Function: forward at line 63\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    63                                               def forward(self, X):\n",
       "    64         1          4.0      4.0      0.0          padded_text, lens, sents_num, imgs = X\n",
       "    65                                                   # 句子编码\n",
       "    66         1        633.0    633.0      0.5          emb = self.word_embedding(padded_text)\n",
       "    67         1     108474.0 108474.0     82.4          si = self.word_encoder(emb, lens)\n",
       "    68         1      11679.0  11679.0      8.9          padded_si = self.padding_layer(si, sents_num)\n",
       "    69                                                   # 文档编码\n",
       "    70         1       3794.0   3794.0      2.9          hi, _ = self.sent_encoder(padded_si, sents_num) # gru\n",
       "    71         1          3.0      3.0      0.0          b, seq, d = hi.shape\n",
       "    72                                                   \n",
       "    73         1        108.0    108.0      0.1          pj = self.img_proj_tanh(self.img_proj_fc(imgs)) # img编码\n",
       "    74         1          7.0      7.0      0.0          pj = pj.view(b, -1, 1, self.visual_attention_size)\n",
       "    75         1         96.0     96.0      0.1          qi = self.sent_proj_tanh(self.sent_proj_fc(hi)) # text 编码\n",
       "    76         1          5.0      5.0      0.0          qi = qi.view(b, 1, seq, d)\n",
       "    77                                                   # vji = (pj * qi + pj) @ self.v # 注意这里保留了没有特征变换的text编码\n",
       "    78         1         54.0     54.0      0.0          vji = (pj * qi) @ self.v # 不保留text编码\n",
       "    79                                           \n",
       "    80         1         20.0     20.0      0.0          masked_vji = torch.full_like(vji, float(\"-inf\")) # b, img_num, seq\n",
       "    81       129        110.0      0.9      0.1          for i in range(b):\n",
       "    82       128       6283.0     49.1      4.8              masked_vji[i,:,:sents_num[i]] = vji[i,:,:sents_num[i]]\n",
       "    83         1         52.0     52.0      0.0          v_score = self.visual_softmax(masked_vji) # b, img_num, seq\n",
       "    84         1          8.0      8.0      0.0          v_score = v_score.view(*v_score.shape, 1)\n",
       "    85         1          4.0      4.0      0.0          hi = hi.view(b, 1, seq, d)\n",
       "    86         1         40.0     40.0      0.0          dj = (v_score * hi).sum(dim=2) # b, img_num, d\n",
       "    87                                                   \n",
       "    88         1        133.0    133.0      0.1          kj = self.doc_proj_tanh(self.doc_proj_fc(dj)) @ self.k # 这里实际已经不需要mask了\n",
       "    89         1         32.0     32.0      0.0          doc_v_score = self.doc_visual_softmax(kj)\n",
       "    90         1          9.0      9.0      0.0          doc_v_score = doc_v_score.view(*doc_v_score.shape, 1)\n",
       "    91         1         29.0     29.0      0.0          d = (dj * doc_v_score).sum(dim=1)\n",
       "    92                                                   \n",
       "    93         1         96.0     96.0      0.1          return self.output_layer(d)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f model.forward model.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch1.6.0]",
   "language": "python",
   "name": "conda-env-torch1.6.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
